This repository tries to perform linear regression without the use of ML libraries like scikit-learn. The purpose of this project is solely for learning purposes, going back to the fundamentals and strengthening the foundation.

The training methodology uses gradient descent as an optimiser and mean squared error as the loss function.

# Constraints
To allow myself for the full learning experience, I imposed the following constraints:
- No LLM help without any exception
- Only theoretical guides are allowed (Practical guides are a strict no).
- The use of libraries are accepted EXCEPT AI/ML libraries (such as scikit-learn)

With the above constraints, I will need to apply the theory on my own. This way, challenges along the way will require critical thinking and difficulities, where learning is prevalent.

# Libraries & Resources
These are the resources and libraries that I found useful during the project (aside from the common ones):
- [Linear Regression in 3 Minutes](https://www.youtube.com/watch?v=3dhcmeOTZ_Q) -> Overview of how linear regression works
- [Stanford's CS229 Lecture 2](https://www.youtube.com/watch?v=4b4MUYve_U8) -> Detailed theory behind linear regression
- [SymPy](https://www.sympy.org/en/index.html) -> Symbolic mathematics in Python. Used mainly for partial derivative of the loss function
- [Abhishek14398's Linear Regression Dataset](https://www.kaggle.com/datasets/abhishek14398/salary-dataset-simple-linear-regression) -> Very simple, 2 features dataset.